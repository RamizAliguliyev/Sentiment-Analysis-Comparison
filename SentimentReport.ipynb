{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87aebd43",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "The script begins by importing several standard Python libraries. These provide the tools needed for text processing, data splitting, and calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d9b03b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import re, random, math, collections, itertools\n",
    "\n",
    "PRINT_ERRORS=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc423d",
   "metadata": {},
   "source": [
    "# Data Loading and Preparation: readFiles\n",
    "Before any model training or testing can occur, all raw data must be read from the disk and structured into a Python-friendly format. The readFiles function is responsible for this entire data ingestion and preparation process. Read data from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f4b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------- Function Definitions ---------------------\n",
    "\n",
    "def readFiles(sentimentDictionary,sentencesTrain,sentencesTest,sentencesNokia):\n",
    "    \"\"\"\n",
    "    Reads all raw data files from disk and populates the dictionaries\n",
    "    passed as arguments.\n",
    "    - sentimentDictionary: Fills with words and their scores (1 or -1).\n",
    "    - sentencesTrain: Fills with ~90% of film reviews for training.\n",
    "    - sentencesTest: Fills with ~10% of film reviews for testing.\n",
    "    - sentencesNokia: Fills with all Nokia reviews for out-of-domain testing.\n",
    "    \"\"\"\n",
    "\n",
    "   # --- 1. Read movie review files ---\n",
    "    # reading pre-labeled input and splitting into lines\n",
    "    posSentences = open('rt-polarity.pos', 'r', encoding=\"ISO-8859-1\")\n",
    "    posSentences = re.split(r'\\n', posSentences.read())\n",
    "\n",
    "    negSentences = open('rt-polarity.neg', 'r', encoding=\"ISO-8859-1\")\n",
    "    negSentences = re.split(r'\\n', negSentences.read())\n",
    "\n",
    "    # --- 2. Read Nokia review files ---\n",
    "    posSentencesNokia = open('nokia-pos.txt', 'r')\n",
    "    posSentencesNokia = re.split(r'\\n', posSentencesNokia.read())\n",
    "\n",
    "    negSentencesNokia = open('nokia-neg.txt', 'r', encoding=\"ISO-8859-1\")\n",
    "    negSentencesNokia = re.split(r'\\n', negSentencesNokia.read())\n",
    "    # --- 3. Read sentiment dictionary files ---\n",
    "    \n",
    "    # Use a list comprehension to read positive words.\n",
    "    # .strip() removes whitespace/newlines.\n",
    "    # 'if line.strip()' filters out empty blank lines.\n",
    "    # 'not line.startswith(\";\")' filters out comment lines.\n",
    "    posDictionary = open('positive-words.txt', 'r', encoding=\"ISO-8859-1\")\n",
    "    posWordList = [line.strip() for line in posDictionary.readlines() if line.strip() and not line.startswith(';')]\n",
    "    posDictionary.close()\n",
    "\n",
    "    # Do the same for the negative words list.\n",
    "    negDictionary = open('negative-words.txt', 'r', encoding=\"ISO-8859-1\")\n",
    "    negWordList = [line.strip() for line in negDictionary.readlines() if line.strip() and not line.startswith(';')] \n",
    "    negDictionary.close()\n",
    "\n",
    "    # --- 4. Populate the master sentiment dictionary with scores ---\n",
    "    for i in posWordList:\n",
    "        sentimentDictionary[i] = 1\n",
    "    for i in negWordList:\n",
    "        sentimentDictionary[i] = -1\n",
    "\n",
    "    # --- 5. Create Training and Test Datsets for Film Reviews ---\n",
    "    # We want to test on sentences we haven't trained on, \n",
    "    # to see how well the model generalises to previously unseen sentences.\n",
    "    \n",
    "    # Create ~90% training / 10% test split of training and test data\n",
    "    for i in posSentences:\n",
    "        # random.randint(1,10) picks a number between 1 and 10.\n",
    "        # '< 2' is true 1 out of 10 times (i.e., when it picks '1').\n",
    "        if random.randint(1,10)<2:\n",
    "            sentencesTest[i]=\"positive\"\n",
    "        else:\n",
    "            sentencesTrain[i]=\"positive\"\n",
    "\n",
    "    for i in negSentences:\n",
    "        if random.randint(1,10)<2:\n",
    "            sentencesTest[i]=\"negative\"\n",
    "        else:\n",
    "            sentencesTrain[i]=\"negative\"\n",
    "\n",
    "   # --- 6. Create Nokia (Out-of-Domain) Datset ---\n",
    "    # No split needed, this is only for testing.\n",
    "    for i in posSentencesNokia:\n",
    "            sentencesNokia[i]=\"positive\"\n",
    "    for i in negSentencesNokia:\n",
    "            sentencesNokia[i]=\"negative\"\n",
    "#----------------------------End of data initialisation ----------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03feb3c7",
   "metadata": {},
   "source": [
    "# Parsing the Sentiment Lexicons\n",
    "This block of code is the direct implementation of Step 2.1 from the assignment. The original script provided empty lists (posWordList = [] and negWordList = []). The task is to replace them with code that correctly reads and parses the dictionary files.\n",
    "\n",
    "The most efficient solution is a list comprehension, which builds a new list by processing each line from the file.\n",
    " ```\n",
    "   posDictionary = open('positive-words.txt', 'r', encoding=\"ISO-8859-1\")\n",
    "    posWordList = [line.strip() for line in posDictionary.readlines() if line.strip() and not line.startswith(';')]\n",
    "    posDictionary.close()\n",
    "\n",
    "    negDictionary = open('negative-words.txt', 'r', encoding=\"ISO-8859-1\")\n",
    "    negWordList = [line.strip() for line in negDictionary.readlines() if line.strip() and not line.startswith(';')] \n",
    "    negDictionary.close()\n",
    "```\n",
    " This is the \"output\" part. For every line that passes the filters, line.strip() is called to remove all leading/trailing whitespace (like spaces, tabs, and the invisible \\n newline character). This gives us a clean word.\n",
    "\n",
    " ``` for line in posDictionary.readlines() : ```This is the loop. It reads the file line by line.\n",
    "\n",
    " ``` if line.strip() and not line.startswith(';') : ``` This line ensures that it don't save empty line and in case of the commets to skip them I use method line.startswith(';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c72d9",
   "metadata": {},
   "source": [
    "# Naive Bayes Model Training: trainBayes\n",
    "This function is the \"learning\" or \"training\" phase of our statistical classifier. Its sole purpose is to run through the sentencesTrain dataset and build the probabilistic model.\n",
    "\n",
    "It calculates the conditional probabilities for every word in the vocabulary, answering the question: \"What is the probability of seeing this word, given the sentiment is positive?\" (and vice-versa for negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "265cc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates p(W|Positive), p(W|Negative) and p(W) for all words in training data\n",
    "def trainBayes(sentencesTrain, pWordPos, pWordNeg, pWord):\n",
    "    \"\"\"\n",
    "    Trains the Naive Bayes model.\n",
    "    This function iterates over the training data to count word occurrences\n",
    "    and then calculates the conditional probabilities P(Word|Positive)\n",
    "    and P(Word|Negative) for every word in the vocabulary.\n",
    "    \n",
    "    Args:\n",
    "        sentencesTrain (dict): The training data (sentence: sentiment).\n",
    "        pWordPos (dict): An empty dict to be filled with P(W|Pos) probabilities.\n",
    "        pWordNeg (dict): An empty dict to be filled with P(W|Neg) probabilities.\n",
    "        pWord (dict): An empty dict to be filled with P(W) probabilities.\n",
    "    \"\"\"\n",
    "    # Dictionaries to store the raw counts of each word  [hash function]\n",
    "    freqPositive = {} \n",
    "    freqNegative = {}\n",
    "    # A set of all unique words in the training data (our vocabulary)\n",
    "    dictionary = {}\n",
    "    # Counters for the total number of words in each class\n",
    "    posWordsTot = 0\n",
    "    negWordsTot = 0\n",
    "    allWordsTot = 0\n",
    "\n",
    "    # --- STAGE 1: COUNTING ---\n",
    "    # iterate through each sentence/sentiment pair in the training data\n",
    "    for sentence, sentiment in sentencesTrain.items():\n",
    "        # Tokenize the sentence into a list of words\n",
    "        wordList = re.findall(r\"[\\w']+\", sentence)\n",
    "        \n",
    "        for word in wordList: # calculate over unigrams\n",
    "            allWordsTot += 1 # keeps count of total words in dataset\n",
    "            if not (word in dictionary):\n",
    "                dictionary[word] = 1\n",
    "            if sentiment==\"positive\" :\n",
    "                posWordsTot += 1 # keeps count of total words in positive class\n",
    "\n",
    "                # keep count of each word in positive context\n",
    "                if not (word in freqPositive):\n",
    "                    freqPositive[word] = 1\n",
    "                else:\n",
    "                    freqPositive[word] += 1    \n",
    "            else:\n",
    "                negWordsTot+=1 # keeps count of total words in negative class\n",
    "                \n",
    "                # keep count of each word in positive context\n",
    "                if not (word in freqNegative):\n",
    "                    freqNegative[word] = 1\n",
    "                else:\n",
    "                    freqNegative[word] += 1\n",
    "\n",
    "    for word in dictionary:\n",
    "        # do some smoothing so that minimum count of a word is 1\n",
    "        if not (word in freqNegative):\n",
    "            freqNegative[word] = 1\n",
    "        if not (word in freqPositive):\n",
    "            freqPositive[word] = 1\n",
    "\n",
    "        # Calculate p(word|positive)\n",
    "        pWordPos[word] = freqPositive[word] / float(posWordsTot)\n",
    "\n",
    "        # Calculate p(word|negative) \n",
    "        pWordNeg[word] = freqNegative[word] / float(negWordsTot)\n",
    "\n",
    "        # Calculate p(word)\n",
    "        pWord[word] = (freqPositive[word] + freqNegative[word]) / float(allWordsTot) \n",
    "\n",
    "#---------------------------End Training ----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c29d2d",
   "metadata": {},
   "source": [
    "The function operates in two main stages:\n",
    "\n",
    "Stage 1: Counting Frequencies: Loop through all training sentences and count every word.\n",
    "\n",
    "Stage 2: Calculating Probabilities: Convert those raw counts into probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8758344e",
   "metadata": {},
   "source": [
    "# Stage 1: Counting Word Frequencies\n",
    "The first part of the function iterates over every (sentence, sentiment) pair in the sentencesTrain dictionary.\n",
    "```\n",
    "# Dictionaries to store the raw counts of each word\n",
    "    freqPositive = {} \n",
    "    freqNegative = {} \n",
    "    dictionary = {} # A set of all unique words in the training data\n",
    "    \n",
    "    # Counters for the total number of words in each class\n",
    "    posWordsTot = 0  \n",
    "    negWordsTot = 0  \n",
    "    allWordsTot = 0  \n",
    "\n",
    "    # --- STAGE 1: COUNTING ---\n",
    "    for sentence, sentiment in sentencesTrain.items():\n",
    "        wordList = re.findall(r\"[\\w']+\", sentence)\n",
    "        \n",
    "        for word in wordList:\n",
    "            allWordsTot += 1\n",
    "            if not (word in dictionary):\n",
    "                dictionary[word] = 1 # Add word to our vocabulary\n",
    "                \n",
    "            if sentiment==\"positive\" :\n",
    "                posWordsTot += 1 \n",
    "                if not (word in freqPositive):\n",
    "                    freqPositive[word] = 1\n",
    "                else:\n",
    "                    freqPositive[word] += 1    \n",
    "            else:\n",
    "                negWordsTot+=1 \n",
    "                if not (word in freqNegative):\n",
    "                    freqNegative[word] = 1\n",
    "                else:\n",
    "                    freqNegative[word] += 1\n",
    "```\n",
    "At the end of this stage, we have:\n",
    "\n",
    "freqPositive / freqNegative: Dictionaries holding the raw count of each word in each class (e.g., freqPositive['great'] = 500).\n",
    "\n",
    "posWordsTot / negWordsTot: The total number of words (not unique) in all positive or negative sentences.\n",
    "\n",
    "dictionary: A set of every unique word encountered, which we call our vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e10f19",
   "metadata": {},
   "source": [
    "# Stage 2: Calculating Probabilities (with Smoothing)\n",
    "The second stage iterates over our new dictionary. It converts the raw counts from Stage 1 into the final probabilities that our model will use.\n",
    "```\n",
    "# --- STAGE 2: CALCULATING PROBABILITIES ---\n",
    "    for word in dictionary:\n",
    "        \n",
    "        # --- Add-One (Laplace) Smoothing ---\n",
    "        if not (word in freqNegative):\n",
    "            freqNegative[word] = 1\n",
    "        if not (word in freqPositive):\n",
    "            freqPositive[word] = 1\n",
    "```\n",
    "This is a critical step. If a word (e.g., \"superb\") appeared in positive reviews but never in a negative one, its freqNegative count would be 0. Later, this would cause a 0-probability error that would break the entire calculation. By adding a \"fake\" count of 1, we ensure every word has a tiny, non-zero probability in both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad092fd",
   "metadata": {},
   "source": [
    "# After smoothing, the final probabilities are calculated:\n",
    "```\n",
    "# Calculate p(word|positive)\n",
    "        pWordPos[word] = freqPositive[word] / float(posWordsTot)\n",
    "\n",
    "        # Calculate p(word|negative) \n",
    "        pWordNeg[word] = freqNegative[word] / float(negWordsTot)\n",
    "\n",
    "        # Calculate p(word)\n",
    "        pWord[word] = (freqPositive[word] + freqNegative[word]) / float(allWordsTot)\n",
    "```\n",
    "At the end of this function, the (previously empty) dictionaries pWordPos, pWordNeg, and pWord are now filled with the probabilities needed to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80b348",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification: testBayes\n",
    "This function is the \"testing\" or \"classification\" phase. It acts as the \"examiner\" for our model. It takes the probabilities calculated by trainBayes and uses them to predict the sentiment of new, unseen sentences from a test set (sentencesTest or sentencesNokia).\n",
    "\n",
    "Its final job is to compare its own predictions against the \"ground truth\" (correct) labels, which allows us to calculate all the performance metrics for Step 2.\n",
    "\n",
    "The function can be broken down into three parts: the core classification logic, the error-printing mechanism, and the final metrics calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db2d87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement naive bayes algorithm\n",
    "# INPUTS:\n",
    "#   sentencesTest is a dictonary with sentences associated with sentiment \n",
    "#   dataName is a string (used only for printing output)\n",
    "#   pWordPos is dictionary storing p(word|positive) for each word\n",
    "#      i.e., pWordPos[\"apple\"] will return a real value for p(\"apple\"|positive)\n",
    "#   pWordNeg is dictionary storing p(word|negative) for each word\n",
    "#   pWord is dictionary storing p(word)\n",
    "#   pPos is a real number containing the fraction of positive reviews in the dataset\n",
    "def testBayes(sentencesTest, dataName, pWordPos, pWordNeg, pWord,pPos):\n",
    "\n",
    "    print(\"Naive Bayes classification for \" + dataName)\n",
    "    pNeg=1-pPos\n",
    "\n",
    "    # These variables will store results\n",
    "    total=0\n",
    "    correct=0\n",
    "    totalpos=0\n",
    "    totalpospred=0\n",
    "    totalneg=0\n",
    "    totalnegpred=0\n",
    "    correctpos=0\n",
    "    correctneg=0\n",
    "\n",
    "    # for each sentence, sentiment pair in the dataset\n",
    "    for sentence, sentiment in sentencesTest.items():\n",
    "        wordList = re.findall(r\"[\\w']+\", sentence)#collect all words\n",
    "\n",
    "        pPosW=pPos\n",
    "        pNegW=pNeg\n",
    "\n",
    "        for word in wordList: # calculate over unigrams\n",
    "            if word in pWord:\n",
    "                if pWord[word]>0.00000001:\n",
    "                    pPosW *=pWordPos[word]\n",
    "                    pNegW *=pWordNeg[word]\n",
    "\n",
    "        prob=0; \n",
    "        # Normalize the scores into a 0-1 probability\n",
    "        # prob = P(Pos|W) / (P(Pos|W) + P(Neg|W))           \n",
    "        if pPosW+pNegW >0:\n",
    "            prob=pPosW/float(pPosW+pNegW)\n",
    "\n",
    "        total+=1\n",
    "        # 'sentiment' is the \"ground truth\" (correct answer)\n",
    "        if sentiment==\"positive\":\n",
    "            totalpos+=1\n",
    "            # 'prob > 0.5' is the model's prediction\n",
    "            if prob>0.5:\n",
    "                correct+=1\n",
    "                correctpos+=1\n",
    "                totalpospred+=1\n",
    "            else:# Ground truth is negative\n",
    "                correct+=0\n",
    "                totalnegpred+=1\n",
    "                if PRINT_ERRORS:\n",
    "                    print (\"ERROR (pos classed as neg %0.2f):\" %prob + sentence)\n",
    "        else:\n",
    "            totalneg+=1\n",
    "            if prob<=0.5:\n",
    "                correct+=1\n",
    "                correctneg+=1\n",
    "                totalnegpred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalpospred+=1\n",
    "                if PRINT_ERRORS:\n",
    "                    print (\"ERROR (neg classed as pos %0.2f):\" %prob + sentence)\n",
    "    # Accuracy = (Correct Predictions) / (Total Predictions)\n",
    "    accuracy = (correct / float(total)) * 100 if total >0 else 0\n",
    "\n",
    "    # --- Positive Class Metrics ---\n",
    "\n",
    "    # Precision (Positive): TP / (TP + FP) -> correctpos / totalpospred\n",
    "    # \"Of all sentences we PREDICTED positive, how many were ACTUALLY positive?\"\n",
    "    pos_precision = (correctpos / float(totalpospred)) * 100 if totalpospred >0 else 0\n",
    "\n",
    "    # Recall (Positive): TP / (TP + FN) -> correctpos / totalpos\n",
    "    # \"Of all ACTUALLY positive sentences, how many did we FIND?\"\n",
    "    pos_recall = (correctpos / float(totalpos)) * 100 if totalpos >0 else 0\n",
    "\n",
    "    # F1-Score (Positive): 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    # The harmonic mean, balancing precision and recall. Good for uneven classes.\n",
    "    pos_f1 = (2 * pos_precision * pos_recall) / (pos_precision + pos_recall) if (pos_precision + pos_recall) >0 else 0\n",
    "\n",
    "    # --- Negative Class Metrics ---\n",
    "    \n",
    "    # Precision (Negative): TN / (TN + FN) -> correctneg / totalnegpred\n",
    "    # \"Of all sentences we PREDICTED negative, how many were ACTUALLY negative?\"\n",
    "    neg_precision = (correctneg / float(totalnegpred)) * 100 if totalnegpred > 0 else 0\n",
    "\n",
    "    # Recall (Negative): TN / (TN + FP) -> correctneg / totalneg\n",
    "    neg_recall = (correctneg / float(totalneg)) * 100 if totalneg > 0 else 0\n",
    "\n",
    "    # F1-Score (Negative): 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    neg_f1 = (2 * neg_precision * neg_recall) / (neg_precision + neg_recall) if (neg_precision + neg_recall) > 0 else 0\n",
    "\n",
    "    # --- Print all the results in a clean format ---\n",
    "    print(f\"\\n--- Results for {dataName} ---\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total})\")\n",
    "    print(\"\\n--- Positive Class ---\")\n",
    "    print(f\"Precision: {pos_precision:.2f}% ({correctpos}/{totalpospred})\")\n",
    "    print(f\"Recall:    {pos_recall:.2f}% ({correctpos}/{totalpos})\")\n",
    "    print(f\"F1-Score:  {pos_f1:.2f}\")\n",
    "    print(\"\\n--- Negative Class ---\")\n",
    "    print(f\"Precision: {neg_precision:.2f}% ({correctneg}/{totalnegpred})\")\n",
    "    print(f\"Recall:    {neg_recall:.2f}% ({correctneg}/{totalneg})\")\n",
    "    print(f\"F1-Score:  {neg_f1:.2f}\")\n",
    "    print(\"--------------------------------\\n\")\n",
    "    # --- END of Step 2 TODO ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457203c8",
   "metadata": {},
   "source": [
    "# Core Classification Logic\n",
    "The function iterates through every (sentence, sentiment) pair in the provided sentencesTest dictionary. For each sentence, it performs the core Naive Bayes calculation.\n",
    "```\n",
    "# ... (metrics counters are initialized to 0) ...\n",
    "\n",
    "    for sentence, sentiment in sentencesTest.items():\n",
    "        wordList = re.findall(r\"[\\w']+\", sentence)\n",
    "\n",
    "        # Start with the base probabilities (e.g., 0.5 for pos, 0.5 for neg)\n",
    "        pPosW=pPos\n",
    "        pNegW=pNeg\n",
    "\n",
    "        # --- This is the Naive Bayes core calculation ---\n",
    "        # P(Pos|Sentence) = P(Pos) * P(w1|Pos) * P(w2|Pos) * ...\n",
    "        for word in wordList:\n",
    "            if word in pWord:\n",
    "                if pWord[word]>0.00000001:\n",
    "                    pPosW *=pWordPos[word]\n",
    "                    pNegW *=pWordNeg[word]\n",
    "```\n",
    "This loop multiplies the probabilities of each word. This is the \"naive\" assumption in actionâ€”it treats each word's probability as independent. After iterating through all words, pPosW and pNegW hold the final (un-normalized) scores.\n",
    "\n",
    "These scores are then normalized into a single 0-to-1 probability:\n",
    "```\n",
    "# Normalize the scores: P(Pos|W) / (P(Pos|W) + P(Neg|W))\n",
    "        if pPosW+pNegW >0:\n",
    "            prob=pPosW/float(pPosW+pNegW)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a586b",
   "metadata": {},
   "source": [
    "# Tallying Results and Printing Errors\n",
    "The function then compares its prediction (prob) to the correct answer (sentiment). It uses this comparison to increment all the counters needed for the metrics (e.g., ```correct, correctpos, totalpospred```).\n",
    "\n",
    "This section also implements the requirement for Step 6: if the PRINT_ERRORS flag is set to 1, the function will print any sentence it classifies incorrectly.\n",
    "```\n",
    "if sentiment==\"positive\":\n",
    "            if prob>0.5:\n",
    "                correct+=1\n",
    "                # ...\n",
    "            else:\n",
    "                # ...\n",
    "                if PRINT_ERRORS: # <-- Step 6\n",
    "                    print (\"ERROR (pos classed as neg %0.2f):\" %prob + sentence)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4478aea3",
   "metadata": {},
   "source": [
    "# Calculating Performance Metrics (Step 2)\n",
    "This final block of code is the implementation of Step 2. It takes all the counters (like correctpos, totalpospred, etc.) and calculates the standard academic metrics.\n",
    "\n",
    "```\n",
    "# --- START of Step 2 TODO: Calculate Performance Metrics ---\n",
    "    \n",
    "    # Accuracy = (Correct Predictions) / (Total Predictions)\n",
    "    accuracy = (correct / float(total)) * 100 if total > 0 else 0\n",
    "    \n",
    "    # Precision (Positive): TP / (TP + FP) -> correctpos / totalpospred\n",
    "    pos_precision = (correctpos / float(totalpospred)) * 100 if totalpospred > 0 else 0\n",
    "    \n",
    "    # Recall (Positive): TP / (TP + FN) -> correctpos / totalpos\n",
    "    pos_recall = (correctpos / float(totalpos)) * 100 if totalpos > 0 else 0\n",
    "    \n",
    "    # F1-Score (Positive): 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    pos_f1 = (2 * pos_precision * pos_recall) / (pos_precision + pos_recall) if (pos_precision + pos_recall) > 0 else 0\n",
    "    \n",
    "    # (Identical calculations are performed for the Negative class)\n",
    "    # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4990d490",
   "metadata": {},
   "source": [
    "# Rule-Based Classification: testDictionary\n",
    "This function is our second classifier: the rule-based or lexicon-based system. This function is the \"baseline\" or \"dumb\" model required for Step 5.\n",
    "\n",
    "Unlike trainBayes, this model does no \"learning\". Its logic is a simple, fixed set of rules:\n",
    "\n",
    "Read a sentence.\n",
    "\n",
    "If a word is in our sentimentDictionary, add its score (+1 or -1).\n",
    "\n",
    "If the final score is above a threshold, classify it as positive.\n",
    "\n",
    "This function is also where we add the performance metrics for Step 5.1 and the error-printing logic for Step 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b3e5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simple classifier that uses a sentiment dictionary to classify \n",
    "# a sentence. For each word in the sentence, if the word is in the positive \n",
    "# dictionary, it adds 1, if it is in the negative dictionary, it subtracts 1. \n",
    "# If the final score is above a threshold, it classifies as \"Positive\", \n",
    "# otherwise as \"Negative\"\n",
    "def testDictionary(sentencesTest, dataName, sentimentDictionary, threshold):\n",
    "\n",
    "    print(\"Dictionary-based classification\")\n",
    "    total=0\n",
    "    correct=0\n",
    "    totalpos=0\n",
    "    totalneg=0\n",
    "    totalpospred=0\n",
    "    totalnegpred=0\n",
    "    correctpos=0\n",
    "    correctneg=0\n",
    "\n",
    "    # Iterate over each sentence and its correct label\n",
    "    for sentence, sentiment in sentencesTest.items():\n",
    "        Words = re.findall(r\"[\\w']+\", sentence)\n",
    "        score=0\n",
    "\n",
    "        # Sum the scores of all known words in the sentence\n",
    "        for word in Words:\n",
    "            if word in sentimentDictionary:\n",
    "               score+=sentimentDictionary[word]\n",
    " \n",
    "        total+=1\n",
    "\n",
    "        # --- Tallying Results ---\n",
    "        # 'sentiment' is the correct answer\n",
    "        if sentiment==\"positive\":\n",
    "            totalpos+=1\n",
    "            # 'score >= threshold' is the model's prediction\n",
    "            if score>=threshold:\n",
    "                correct+=1\n",
    "                correctpos+=1\n",
    "                totalpospred+=1\n",
    "            else:# Predict negative\n",
    "                correct+=0\n",
    "                totalnegpred+=1\n",
    "        else:\n",
    "            totalneg+=1\n",
    "            # STEP 6: Check for printing errors\n",
    "            if score<threshold:\n",
    "                correct+=1\n",
    "                correctneg+=1\n",
    "                totalnegpred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalpospred+=1\n",
    "    # TODO for Step 5: Add some code here to calculate and print: (1) accuracy; (2) precision and recall for the positive class; \n",
    "    # (3) precision and recall for the negative class; (4) F1 score;\n",
    "     # Accuracy = (Correct Predictions) / (Total Predictions)\n",
    "    accuracy = (correct / float(total)) * 100 if total > 0 else 0\n",
    "    \n",
    "    # --- Positive Class Metrics ---\n",
    "    # Precision (Positive): TP / (TP + FP) -> correctpos / totalpos\n",
    "    pos_precision = (correctpos / float(totalpospred)) * 100 if totalpospred > 0 else 0\n",
    "\n",
    "    # Recall (Positive): TP / (TP + FN) -> correctpos / totalpos\n",
    "    pos_recall = (correctpos / float(totalpos)) * 100 if totalpos > 0 else 0\n",
    "\n",
    "    # F1-Score (Positive): 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    pos_f1 = (2 * pos_precision * pos_recall) / (pos_precision + pos_recall) if (pos_precision + pos_recall) > 0 else 0\n",
    "    \n",
    "    # --- Negative Class Metrics ---\n",
    "    # Precision (Negative): TN / (TN + FN) -> correctneg / totalneg\n",
    "    neg_precision = (correctneg / float(totalnegpred)) * 100 if totalnegpred > 0 else 0\n",
    "\n",
    "    # Recall (Negative): TN / (TN + FP) -> correctneg / totalneg\n",
    "    neg_recall = (correctneg / float(totalneg)) * 100 if totalneg > 0 else 0\n",
    "\n",
    "    # F1-Score (Negative): 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    neg_f1 = (2 * neg_precision * neg_recall) / (neg_precision + neg_recall) if (neg_precision + neg_recall) > 0 else 0\n",
    "\n",
    "    # --- Print all the results in a clean format ---\n",
    "    print(f\"\\n--- Results for {dataName} ---\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total})\")\n",
    "    print(\"\\n--- Positive Class ---\")\n",
    "    print(f\"Precision: {pos_precision:.2f}% ({correctpos}/{totalpospred})\")\n",
    "    print(f\"Recall:    {pos_recall:.2f}% ({correctpos}/{totalpos})\")\n",
    "    print(f\"F1-Score:  {pos_f1:.2f}\")\n",
    "    print(\"\\n--- Negative Class ---\")\n",
    "    print(f\"Precision: {neg_precision:.2f}% ({correctneg}/{totalnegpred})\")\n",
    "    print(f\"Recall:    {neg_recall:.2f}% ({correctneg}/{totalneg})\")\n",
    "    print(f\"F1-Score:  {neg_f1:.2f}\")\n",
    "    print(\"--------------------------------\\n\")\n",
    "    # --- END of Step 5 TODO ---\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033c4825",
   "metadata": {},
   "source": [
    "# Core Classification Logic\n",
    "The function iterates through each sentence and tokenizes it. It then loops through the words, checking if any exist in the ```sentimentDictionary```.\n",
    "\n",
    "```\n",
    "# ... (metrics counters are initialized to 0) ...\n",
    "    \n",
    "    for sentence, sentiment in sentencesTest.items():\n",
    "        Words = re.findall(r\"[\\w']+\", sentence)\n",
    "        score=0\n",
    "        \n",
    "        # Sum the scores of all known words in the sentence\n",
    "        for word in Words:\n",
    "            if word in sentimentDictionary:\n",
    "               score+=sentimentDictionary[word] # Add +1 or -1\n",
    "```\n",
    "After checking all words, the score variable holds the final sentiment value for the sentence (e.g., 2, -1, 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a04288d",
   "metadata": {},
   "source": [
    "# Tallying and Error Printing\n",
    "The final ```score``` is then compared against the ```threshold``` (which is set to ```1``` in our script) to make a prediction. This prediction is compared to the ```sentiment``` (ground truth) to tally the results.\n",
    "\n",
    "This block also contains the ```if PRINT_ERRORS:``` check required by Step 6, which was added to the function.\n",
    "```\n",
    "if sentiment==\"positive\":\n",
    "            totalpos+=1\n",
    "            if score>=threshold:\n",
    "                correct+=1\n",
    "                # ...\n",
    "            else: # Predict negative\n",
    "                correct+=0\n",
    "                totalnegpred+=1\n",
    "                if PRINT_ERRORS: # <-- Step 6\n",
    "                    print (f\"ERROR (pos classed as neg, score {score}): {sentence}\")\n",
    "        else: # Ground truth is negative\n",
    "            # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b3a00",
   "metadata": {},
   "source": [
    "# Calculating Performance Metrics\n",
    "Finally, just like in ```testBayes```, this block implements the requirements of Step 5 by calculating and printing the full set of metrics (Accuracy, Precision, Recall, F1).\n",
    "```\n",
    "# --- START of Step 5: Calculate Performance Metrics ---\n",
    "    \n",
    "    # Accuracy = (Correct Predictions) / (Total Predictions)\n",
    "    accuracy = (correct / float(total)) * 100 if total > 0 else 0\n",
    "    \n",
    "    # Precision (Positive): TP / (TP + FP)\n",
    "    pos_precision = (correctpos / float(totalpospred)) * 100 if totalpospred > 0 else 0\n",
    "    \n",
    "    # (... all other metrics calculations ...)\n",
    "    # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f862b7b",
   "metadata": {},
   "source": [
    "# Improving the Rule-Based System\n",
    "``` testDictionaryImproved ```\n",
    "The reason for creating this new function is that the simple ```testDictionary``` method was too naive. It only counted +1 or -1 for words it found, ignoring all other linguistic context. This was especially problematic for film reviews. The Error Analysis showed it would fail on simple phrases, for example:\n",
    "\n",
    "- \"not good\": Classified as Positive (Score: +1)\n",
    "\n",
    "- \"NOT a masterpiece\": Classified as Positive (Score: +1)\n",
    "\n",
    "The baseline model saw both \"not good\" and \"very good\" as having the exact same +1 score as \"good\".\n",
    "\n",
    "The solution was to create testDictionaryImproved which adds a layer of linguistic rules to understand the context of a sentiment word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "981a6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For step 5.3: Improved dictionary-based classifier with negation handling\n",
    "#Negotiation handling: If a negation word is found, invert the sentiment scores of the next three words.\n",
    "def testDictionaryImproved(sentencesTest, dataName, sentimentDictionary, threshold):\n",
    "    \"\"\"\n",
    "    Performs rule-based classification (like testDictionary), but includes\n",
    "    a simple negation-handling rule.\n",
    "    \n",
    "    This function extends the base classifier by adding a \"negation window\".\n",
    "    When a negation word (e..g, \"not\", \"n't\") is found, the sentiment\n",
    "    score of the next N words (e.g., 3) is inverted. This is a form of\n",
    "    linguistic generalization, as required by Step 5.3.\n",
    "    \"\"\"\n",
    "    print(f\"IMPROVED Dictionary-based classification for: {dataName}\")\n",
    "    total=0\n",
    "    correct=0\n",
    "    totalpos=0\n",
    "    totalneg=0\n",
    "    totalpospred=0\n",
    "    totalnegpred=0\n",
    "    correctpos=0\n",
    "    correctneg=0\n",
    "    \n",
    "    # Define negation words\n",
    "    negation_words = {\"not\", \"n't\", \"no\", \"never\", \"cannot\", \"can't\", \"don't\", \"doesn't\", \"didn't\"}\n",
    "\n",
    "    for sentence, sentiment in sentencesTest.items():\n",
    "        Words = re.findall(r\"[\\w']+\", sentence.lower()) # process in lowercase\n",
    "        score=0\n",
    "        negation_window = 0 # How many words forward the negation applies\n",
    "\n",
    "        for word in Words:\n",
    "            if word in negation_words:\n",
    "                negation_window = 3 # Apply negation to next 3 words\n",
    "            \n",
    "            if word in sentimentDictionary:\n",
    "                word_score = sentimentDictionary[word]\n",
    "                if negation_window > 0:\n",
    "                    word_score = -word_score # Invert the score\n",
    "                score += word_score\n",
    "            \n",
    "            # Decrement the window\n",
    "            if negation_window > 0:\n",
    "                negation_window -= 1\n",
    " \n",
    "        total+=1\n",
    "        if sentiment==\"positive\":\n",
    "            totalpos+=1\n",
    "            if score>=threshold:\n",
    "                correct+=1\n",
    "                correctpos+=1\n",
    "                totalpospred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalnegpred+=1\n",
    "                if PRINT_ERRORS:\n",
    "                    print (f\"ERROR (pos classed as neg, score {score}): {sentence}\")\n",
    "        else:\n",
    "            totalneg+=1\n",
    "            if score<threshold:\n",
    "                correct+=1\n",
    "                correctneg+=1\n",
    "                totalnegpred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalpospred+=1\n",
    "                if PRINT_ERRORS:\n",
    "                    print (f\"ERROR (neg classed as pos, score {score}): {sentence}\") \n",
    "\n",
    "    # --- Metrics calculations ---\n",
    "\n",
    "    # Accuracy = (Correct Predictions) / (Total Predictions)\n",
    "    accuracy = (correct / float(total)) * 100 if total > 0 else 0\n",
    "\n",
    "    # --- Positive Class Metrics ---\n",
    "    # Precision (Positive): TP / (TP + FP) -> correctpos / totalpos\n",
    "    pos_precision = (correctpos / float(totalpospred)) * 100 if totalpospred > 0 else 0\n",
    "\n",
    "    # Recall (Positive): TP / (TP + FN) -> correctpos / totalpos\n",
    "    pos_recall = (correctpos / float(totalpos)) * 100 if totalpos > 0 else 0\n",
    "\n",
    "    # F1-Score (Positive): 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    pos_f1 = (2 * pos_precision * pos_recall) / (pos_precision + pos_recall) if (pos_precision + pos_recall) > 0 else 0\n",
    "    \n",
    "    # --- Negative Class Metrics ---\n",
    "    # Precision (Negative): TN / (TN + FN) -> correctneg / totalneg\n",
    "    neg_precision = (correctneg / float(totalnegpred)) * 100 if totalnegpred > 0 else 0\n",
    "\n",
    "    # Recall (Negative): TN / (TN + FP) -> correctneg / totalneg\n",
    "    neg_recall = (correctneg / float(totalneg)) * 100 if totalneg > 0 else 0\n",
    "\n",
    "    # F1-Score (Negative): 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    neg_f1 = (2 * neg_precision * neg_recall) / (neg_precision + neg_recall) if (neg_precision + neg_recall) > 0 else 0\n",
    "\n",
    "    # --- Print all the results in a clean format ---\n",
    "    print(f\"\\n--- Results for {dataName} ---\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total})\")\n",
    "    print(\"\\n--- Positive Class ---\")\n",
    "    print(f\"Precision: {pos_precision:.2f}% ({correctpos}/{totalpospred})\")\n",
    "    print(f\"Recall:    {pos_recall:.2f}% ({correctpos}/{totalpos})\")\n",
    "    print(f\"F1-Score:  {pos_f1:.2f}\")\n",
    "    print(\"\\n--- Negative Class ---\")\n",
    "    print(f\"Precision: {neg_precision:.2f}% ({correctneg}/{totalnegpred})\")\n",
    "    print(f\"Recall:    {neg_recall:.2f}% ({correctneg}/{totalneg})\")\n",
    "    print(f\"F1-Score:  {neg_f1:.2f}\")\n",
    "    print(\"--------------------------------\\n\")\n",
    "# --- END of Step 5.3 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c4f3e",
   "metadata": {},
   "source": [
    "# The New Linguistic Rules\n",
    "This function is \"smarter\" in one specific way: it understands negation words.\n",
    "\n",
    "First, we define a set of these words for a very fast lookup:\n",
    "```negation_words = {\"not\", \"n't\", \"no\", \"never\", \"cannot\", \"can't\", \"don't\", \"doesn't\", \"didn't\"}```\n",
    "## The Core Logic Explained\n",
    "The function loops through each word, managing one \"state\" variable:\n",
    "\n",
    "- negation_window: A counter, which we set to 3. This represents that negation (like \"not\") affects the next 3 words.\n",
    "```\n",
    "for word in Words:\n",
    "            \n",
    "            # 1. Check if the word is a LINGUISTIC MODIFIER\n",
    "            if word in negation_words:\n",
    "                negation_window = 3 # Start the 3-word negation window\n",
    "                continue # This word has no score, so move to the next word\n",
    "            \n",
    "            # (There are NO intensifiers/diminishers in this version)\n",
    "            \n",
    "            # 2. If the word is NOT a modifier, check if it's a SENTIMENT word\n",
    "            if word in sentimentDictionary:\n",
    "                word_score = sentimentDictionary[word] # Get base score (+1 or -1)\n",
    "                \n",
    "                # 3. Apply the negation rule\n",
    "                if negation_window > 0:\n",
    "                    word_score = -word_score # Invert the score (e.g., +1 becomes -1)\n",
    "                \n",
    "                score += word_score\n",
    "                \n",
    "            # 4. Decrement the negation window on every loop\n",
    "            if negation_window > 0:\n",
    "                negation_window -= 1\n",
    "```\n",
    "This logic is simple and effective. For the phrase \"not very good\":\n",
    "\n",
    "1. not sets negation_window = 3.\n",
    "\n",
    "2. very: negation_window changes to 2\n",
    "\n",
    "3. good (+1) is found.\n",
    "\n",
    "4. The negation_window (which > 0) inverts its score to -1.\n",
    "\n",
    "5. The final score is -1.0 (instead of  +1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f14e7c",
   "metadata": {},
   "source": [
    "# The Core Logic: Calculating ```P(Positive|Word)```\n",
    "\n",
    "The function iterates through every word in the model's vocabulary. For each one, it calculates P(Pos|Word) and stores it in a new dictionary called predictPower.\n",
    "\n",
    "The calculation is a simplified version of Bayes' Theorem: P(Pos|W) = P(W|Pos) / (P(W|Pos) + P(W|Neg))\n",
    "\n",
    "## Sorting and Printing Results:\n",
    "After calculating the P(Pos|Word) for all ~20,000 words, the function finds the most useful ones by sorting this dictionary.\n",
    "\n",
    "```head:```: This list contains the n words with the lowest probabilities (closest to 0.0), making them the strongest Negative predictors.\n",
    "\n",
    "```tail```: This list contains the n words with the highest probabilities (closest to 1.0), making them the strongest Positive predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd4dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out n most useful predictors\n",
    "def mostUseful(pWordPos, pWordNeg, pWord, n):\n",
    "    predictPower={}\n",
    "    for word in pWord:\n",
    "        if pWordNeg[word]<0.0000001:\n",
    "            predictPower[word]=1000000000\n",
    "        else:\n",
    "            predictPower[word]=pWordPos[word] / (pWordPos[word] + pWordNeg[word])\n",
    "            \n",
    "    sortedPower = sorted(predictPower, key=predictPower.get)\n",
    "    head, tail = sortedPower[:n], sortedPower[len(predictPower)-n:]\n",
    "    print (\"NEGATIVE:\")\n",
    "    print (head)\n",
    "    print (\"\\nPOSITIVE:\")\n",
    "    print (tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694f111a",
   "metadata": {},
   "source": [
    "# Main Script: The Control Panel\n",
    "This final block of code is not a function. It is the main script that controls the entire experiment. It runs from top to bottom and calls all the functions we've defined to generate the results for report.\n",
    "\n",
    "## Stage 1: Initialization\n",
    "First, we initialize all the master dictionaries as empty. These will be \"filled in\" by our helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e3bfc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- Main Script --------------------------\n",
    "\n",
    "\n",
    "sentimentDictionary={} # {} initialises a dictionary [hash function]\n",
    "sentencesTrain={}\n",
    "sentencesTest={}\n",
    "sentencesNokia={}\n",
    "\n",
    "#initialise datasets and dictionaries\n",
    "readFiles(sentimentDictionary,sentencesTrain,sentencesTest,sentencesNokia)\n",
    "\n",
    "pWordPos={} # p(W|Positive)\n",
    "pWordNeg={} # p(W|Negative)\n",
    "pWord={}    # p(W) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6908706",
   "metadata": {},
   "source": [
    "# Naive Bayes \"Learn & Test\"\n",
    "This block is for the statistical model.\n",
    "\n",
    "First, we must call trainBayes. This is the \"learning\" step. It populates the pWordPos and pWordNeg dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99da26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build conditional probabilities using training data\n",
    "trainBayes(sentencesTrain, pWordPos, pWordNeg, pWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37760d4f",
   "metadata": {},
   "source": [
    "Testing: Now that the model is trained, we test it on all three datasets to get our results for Steps 2 & 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afa066a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classification for Films (Train Data, Naive Bayes)\t\n",
      "\n",
      "--- Results for Films (Train Data, Naive Bayes)\t ---\n",
      "Accuracy: 88.83% (8548/9623)\n",
      "\n",
      "--- Positive Class ---\n",
      "Precision: 89.29% (4225/4732)\n",
      "Recall:    88.15% (4225/4793)\n",
      "F1-Score:  88.71\n",
      "\n",
      "--- Negative Class ---\n",
      "Precision: 88.39% (4323/4891)\n",
      "Recall:    89.50% (4323/4830)\n",
      "F1-Score:  88.94\n",
      "--------------------------------\n",
      "\n",
      "Naive Bayes classification for Films  (Test Data, Naive Bayes)\t\n",
      "\n",
      "--- Results for Films  (Test Data, Naive Bayes)\t ---\n",
      "Accuracy: 77.31% (804/1040)\n",
      "\n",
      "--- Positive Class ---\n",
      "Precision: 78.71% (414/526)\n",
      "Recall:    76.95% (414/538)\n",
      "F1-Score:  77.82\n",
      "\n",
      "--- Negative Class ---\n",
      "Precision: 75.88% (390/514)\n",
      "Recall:    77.69% (390/502)\n",
      "F1-Score:  76.77\n",
      "--------------------------------\n",
      "\n",
      "Naive Bayes classification for Nokia   (All Data,  Naive Bayes)\t\n",
      "\n",
      "--- Results for Nokia   (All Data,  Naive Bayes)\t ---\n",
      "Accuracy: 57.89% (154/266)\n",
      "\n",
      "--- Positive Class ---\n",
      "Precision: 77.21% (105/136)\n",
      "Recall:    56.45% (105/186)\n",
      "F1-Score:  65.22\n",
      "\n",
      "--- Negative Class ---\n",
      "Precision: 37.69% (49/130)\n",
      "Recall:    61.25% (49/80)\n",
      "F1-Score:  46.67\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run naive bayes classifier on datasets\n",
    "testBayes(sentencesTrain,  \"Films (Train Data, Naive Bayes)\\t\", pWordPos, pWordNeg, pWord,0.5)\n",
    "testBayes(sentencesTest,  \"Films  (Test Data, Naive Bayes)\\t\", pWordPos, pWordNeg, pWord,0.5)\n",
    "testBayes(sentencesNokia, \"Nokia   (All Data,  Naive Bayes)\\t\", pWordPos, pWordNeg, pWord,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828bc2ec",
   "metadata": {},
   "source": [
    "# Rule-Based \"Test & Improve\"\n",
    "This block is for the rule-based model. It has no \"training\" step.\n",
    "\n",
    "Baseline Test: First, we test the \"naive\" testDictionary on all datasets. This gives us our baseline scores (e.g., the 64.14%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7c52fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary-based classification\n",
      "\n",
      "--- Results for Films (Train Data, Rule-Based)\t ---\n",
      "Accuracy: 65.50% (6303/9623)\n",
      "\n",
      "--- Positive Class ---\n",
      "Precision: 68.28% (2751/4029)\n",
      "Recall:    57.40% (2751/4793)\n",
      "F1-Score:  62.37\n",
      "\n",
      "--- Negative Class ---\n",
      "Precision: 63.50% (3552/5594)\n",
      "Recall:    73.54% (3552/4830)\n",
      "F1-Score:  68.15\n",
      "--------------------------------\n",
      "\n",
      "Dictionary-based classification\n",
      "\n",
      "--- Results for Films  (Test Data, Rule-Based)\t ---\n",
      "Accuracy: 62.88% (654/1040)\n",
      "\n",
      "--- Positive Class ---\n",
      "Precision: 67.76% (290/428)\n",
      "Recall:    53.90% (290/538)\n",
      "F1-Score:  60.04\n",
      "\n",
      "--- Negative Class ---\n",
      "Precision: 59.48% (364/612)\n",
      "Recall:    72.51% (364/502)\n",
      "F1-Score:  65.35\n",
      "--------------------------------\n",
      "\n",
      "Dictionary-based classification\n",
      "\n",
      "--- Results for Nokia   (All Data, Rule-Based)\t ---\n",
      "Accuracy: 79.70% (212/266)\n",
      "\n",
      "--- Positive Class ---\n",
      "Precision: 88.37% (152/172)\n",
      "Recall:    81.72% (152/186)\n",
      "F1-Score:  84.92\n",
      "\n",
      "--- Negative Class ---\n",
      "Precision: 63.83% (60/94)\n",
      "Recall:    75.00% (60/80)\n",
      "F1-Score:  68.97\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run sentiment dictionary based classifier on datasets\n",
    "testDictionary(sentencesTrain,  \"Films (Train Data, Rule-Based)\\t\", sentimentDictionary, 1)\n",
    "testDictionary(sentencesTest,  \"Films  (Test Data, Rule-Based)\\t\",  sentimentDictionary, 1)\n",
    "testDictionary(sentencesNokia, \"Nokia   (All Data, Rule-Based)\\t\",  sentimentDictionary, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40bade4",
   "metadata": {},
   "source": [
    "# Improved Test\n",
    "Improved Test: Finally, we test our testDictionaryImproved function. This gives us our \"improved\" scores (e.g., the 64.43%) so we can compare them to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a129f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RUNNING IMPROVED RULE-BASED CLASSIFIER (STEP 5.3)\n",
      "\n",
      "IMPROVED Dictionary-based classification for: Films (Train Data, Improved Rule-Based)\t\n",
      "\n",
      "--- Results for Films (Train Data, Improved Rule-Based)\t ---\n",
      "Accuracy: 65.77% (6329/9623)\n",
      "\n",
      "--- Positive Class ---\n",
      "Precision: 68.80% (2743/3987)\n",
      "Recall:    57.23% (2743/4793)\n",
      "F1-Score:  62.48\n",
      "\n",
      "--- Negative Class ---\n",
      "Precision: 63.63% (3586/5636)\n",
      "Recall:    74.24% (3586/4830)\n",
      "F1-Score:  68.53\n",
      "--------------------------------\n",
      "\n",
      "IMPROVED Dictionary-based classification for: Films  (Test Data, Improved Rule-Based)\t\n",
      "\n",
      "--- Results for Films  (Test Data, Improved Rule-Based)\t ---\n",
      "Accuracy: 63.08% (656/1040)\n",
      "\n",
      "--- Positive Class ---\n",
      "Precision: 68.08% (290/426)\n",
      "Recall:    53.90% (290/538)\n",
      "F1-Score:  60.17\n",
      "\n",
      "--- Negative Class ---\n",
      "Precision: 59.61% (366/614)\n",
      "Recall:    72.91% (366/502)\n",
      "F1-Score:  65.59\n",
      "--------------------------------\n",
      "\n",
      "IMPROVED Dictionary-based classification for: Nokia   (All Data, Improved Rule-Based)\t\n",
      "\n",
      "--- Results for Nokia   (All Data, Improved Rule-Based)\t ---\n",
      "Accuracy: 82.71% (220/266)\n",
      "\n",
      "--- Positive Class ---\n",
      "Precision: 92.17% (153/166)\n",
      "Recall:    82.26% (153/186)\n",
      "F1-Score:  86.93\n",
      "\n",
      "--- Negative Class ---\n",
      "Precision: 67.00% (67/100)\n",
      "Recall:    83.75% (67/80)\n",
      "F1-Score:  74.44\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRUNNING IMPROVED RULE-BASED CLASSIFIER (STEP 5.3)\\n\")\n",
    "testDictionaryImproved(sentencesTrain,  \"Films (Train Data, Improved Rule-Based)\\t\", sentimentDictionary, 1)\n",
    "testDictionaryImproved(sentencesTest,  \"Films  (Test Data, Improved Rule-Based)\\t\",  sentimentDictionary, 1)\n",
    "testDictionaryImproved(sentencesNokia, \"Nokia   (All Data, Improved Rule-Based)\\t\",  sentimentDictionary, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa1055a",
   "metadata": {},
   "source": [
    "Analysis (Step 4): This call runs mostUseful. It analyzes the probabilities that trainBayes just calculated and prints the top 100 predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e891776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE:\n",
      "['stupid', 'generic', 'unfunny', 'routine', 'badly', 'mediocre', 'supposed', 'poorly', 'boring', 'stale', 'disguise', 'pointless', 'bore', 'unless', 'mindless', 'annoying', 'shoot', 'meandering', 'apparently', 'tiresome', 'chan', 'offensive', 'plodding', 'dull', 'inept', 'excuse', 'animal', 'harvard', 'lousy', 'uninspired', 'mixed', 'junk', 'waste', 'sloppy', 'horrible', 'trite', 'wasted', 'fatal', 'sadly', 'cliched', 'product', 'incoherent', 'lifeless', 'pinocchio', 'pretentious', 'ill', 'stealing', 'frank', 'lame', 'amateurish', 'banal', 'pathetic', 'missed', 'ballistic', 'stiff', 'seagal', 'conceived', 'soggy', 'tv', 'trapped', 'sentiment', 'bother', 'cable', 'flat', 'obnoxious', 'meant', 'witless', 'disbelief', 'unintentional', 'putting', 'pile', 'crass', 'comparison', 'produce', 'choppy', 'crap', 'listless', 'unimaginative', 'inane', 'unnecessary', 'sara', 'impostor', 'tired', 'numbers', 'fails', 'resembles', 'busy', 'warning', 'smug', 'wannabe', 'suffers', 'serving', 'imitation', 'unfocused', 'bears', 'drag', 'settles', 'contains', 'arts', 'relentlessly']\n",
      "\n",
      "POSITIVE:\n",
      "['stylistic', 'delicious', 'smartly', 'gradually', 'melancholy', 'marvel', 'resist', 'ramsay', 'portrayal', 'encounter', 'desperation', 'journey', 'vivid', 'haunting', 'beauty', 'grandeur', 'undeniably', 'russian', 'potent', 'droll', 'understands', 'unflinching', 'speaks', 'loving', 'frailty', 'transcends', 'integrity', 'washington', 'current', 'nuanced', 'ingenious', 'deft', 'explores', 'delightfully', 'smarter', 'joyous', 'touching', 'warm', 'thoughtful', 'helps', 'masterful', 'lane', 'startling', 'bourne', 'lovers', 'format', 'aware', 'poem', 'intimate', 'jealousy', 'pianist', 'powerful', 'visceral', 'iranian', 'record', 'richly', 'subversive', 'answers', 'hopeful', 'sadness', 'evocative', 'playful', 'resonant', 'aspects', 'tour', 'spare', 'sides', 'heartbreaking', 'timely', 'wry', 'unfolds', 'martha', 'lively', 'captivating', 'grown', 'pleasures', 'intense', 'provides', 'gem', 'polished', 'respect', 'vividly', 'heartwarming', 'captures', 'tender', 'detailed', 'ages', 'wonderfully', 'mesmerizing', 'chilling', 'refreshingly', 'realistic', 'riveting', 'refreshing', 'affecting', 'unexpected', 'inventive', 'unique', 'wonderful', 'engrossing']\n"
     ]
    }
   ],
   "source": [
    "# print most useful words\n",
    "mostUseful(pWordPos, pWordNeg, pWord, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
